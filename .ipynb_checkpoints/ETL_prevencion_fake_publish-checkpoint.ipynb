{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Lista de mensajes\n",
    "mensajes = []\n",
    "\n",
    "# Generar mensajes aleatorios\n",
    "for i in range(3000):\n",
    "    if random.choice([True, False]):\n",
    "        # Publicidad legítima\n",
    "        mensaje = fake.sentence(nb_words=10)\n",
    "        mensajes.append((True, mensaje))\n",
    "    else:\n",
    "        # Publicidad engañosa y estafa\n",
    "        mensaje = fake.text(max_nb_chars=100)\n",
    "        mensajes.append((False, mensaje))\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(mensajes, columns=['clase', 'mensaje'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se guardará el archivo CSV\n",
    "path = r\"C:\\Users\\isabe\\Desktop\\todo\\python\\Proyectos personales\\prediccion_de_estafas_online\"\n",
    "\n",
    "# Verificar si el directorio existe, si no, crearlo\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Nombre del archivo CSV\n",
    "filename = \"dataframe.csv\"\n",
    "\n",
    "# Guardar DataFrame como archivo CSV\n",
    "df.to_csv(os.path.join(path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_tokenizar_texto(texto):\n",
    "    # Eliminar signos de puntuación\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    # Eliminar espacios duplicados\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    # Tokenizar texto en palabras\n",
    "    tokens = word_tokenize(texto)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['mensaje'].apply(limpiar_tokenizar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar stopwords en inglés si aún no se han descargado\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Obtener lista de stopwords en inglés\n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "# Eliminar stopwords de la columna \"tokens\"\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.lower() not in stopwords_english])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener lista plana de todos los tokens\n",
    "tokens_list = [word for tokens in df['tokens'] for word in tokens]\n",
    "\n",
    "# Contar frecuencia de cada token\n",
    "frecuencias = Counter(tokens_list)\n",
    "\n",
    "# Crear gráfica de líneas con tamaño personalizado\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(list(frecuencias.keys()), list(frecuencias.values()))\n",
    "\n",
    "# Configurar etiquetas de los ejes y título de la gráfica\n",
    "ax.set_xlabel('Tokens')\n",
    "ax.set_ylabel('Frecuencia')\n",
    "ax.set_title('Frecuencia de Tokens en el DataFrame')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      porcentaje_verdadero       palabra  porcentaje_falso\n",
      "0                 0.124991           run          0.169450\n",
      "1                 0.111103          main          0.169450\n",
      "2                 0.138879         voice          0.139191\n",
      "3                 0.138879      Congress          0.139191\n",
      "4                 0.159711          seat          0.114984\n",
      "...                    ...           ...               ...\n",
      "1895              0.000000     Different          0.006052\n",
      "1896              0.000000  Particularly          0.006052\n",
      "1897              0.006944          Best          0.000000\n",
      "1898              0.000000          Unit          0.006052\n",
      "1899              0.000000    Commercial          0.006052\n",
      "\n",
      "[1900 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Obtener lista plana de todos los tokens\n",
    "tokens_list = [word for tokens in df['tokens'] for word in tokens]\n",
    "\n",
    "# Contar frecuencia de cada token\n",
    "frecuencias = Counter(tokens_list)\n",
    "\n",
    "# Obtener las 30 palabras más comunes\n",
    "top_1900 = frecuencias.most_common(1900)\n",
    "\n",
    "# Inicializar listas vacías para el porcentaje de aparición en mensajes verdaderos y falsos\n",
    "porcentaje_verdadero = []\n",
    "porcentaje_falso = []\n",
    "\n",
    "# Calcular el porcentaje de aparición en mensajes verdaderos y falsos para cada palabra\n",
    "for palabra, frecuencia in top_1900:\n",
    "    verdadero = df.loc[df['clase'] == True, 'tokens'].apply(lambda tokens: palabra in tokens).sum() / df.loc[df['clase'] == True, 'tokens'].apply(len).sum() * 100\n",
    "    falso = df.loc[df['clase'] == False, 'tokens'].apply(lambda tokens: palabra in tokens).sum() / df.loc[df['clase'] == False, 'tokens'].apply(len).sum() * 100\n",
    "    porcentaje_verdadero.append(verdadero)\n",
    "    porcentaje_falso.append(falso)\n",
    "\n",
    "# Crear el DataFrame con las tres columnas requeridas\n",
    "data = {'porcentaje_verdadero': porcentaje_verdadero, 'palabra': [palabra for palabra, frecuencia in top_1900], 'porcentaje_falso': porcentaje_falso}\n",
    "df_resultado = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     porcentaje_verdadero       palabra porcentaje_falso\n",
      "0              1249913200           run       1694504962\n",
      "1              1111033956          main       1694504962\n",
      "2              1388792445         voice       1391914791\n",
      "3              1388792445      Congress       1391914791\n",
      "4              1597111312          seat       1149842653\n",
      "...                   ...           ...              ...\n",
      "1895           0000000000     Different       0060518034\n",
      "1896           0000000000  Particularly       0060518034\n",
      "1897           0069439622          Best       0000000000\n",
      "1898           0000000000          Unit       0060518034\n",
      "1899           0000000000    Commercial       0060518034\n",
      "\n",
      "[1900 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cambiar la notación científica y mover la coma dos espacios dentro de las columnas\n",
    "df_resultado['porcentaje_verdadero'] = df_resultado['porcentaje_verdadero'].apply(lambda x: '{:.10f}'.format(x).replace('.', ',')[2:])\n",
    "df_resultado['porcentaje_falso'] = df_resultado['porcentaje_falso'].apply(lambda x: '{:.10f}'.format(x).replace('.', ',')[2:])\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     porcentaje_verdadero       palabra porcentaje_falso\n",
      "0                   12499           run            16945\n",
      "1                   11110          main            16945\n",
      "2                   13887         voice            13919\n",
      "3                   13887      Congress            13919\n",
      "4                   15971          seat            11498\n",
      "...                   ...           ...              ...\n",
      "1895                00000     Different            00605\n",
      "1896                00000  Particularly            00605\n",
      "1897                00694          Best            00000\n",
      "1898                00000          Unit            00605\n",
      "1899                00000    Commercial            00605\n",
      "\n",
      "[1900 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Eliminar los últimos 5 números de las columnas de porcentaje\n",
    "df_resultado['porcentaje_verdadero'] = df_resultado['porcentaje_verdadero'].astype(str).apply(lambda x: x[:-5])\n",
    "df_resultado['porcentaje_falso'] = df_resultado['porcentaje_falso'].astype(str).apply(lambda x: x[:-5])\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['porcentaje_verdadero', 'palabra', 'porcentaje_falso'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultado.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ingrese el texto a evaluar:  Finance is a professional specialization. It’s not uniquely difficult (or fun), but you shouldn’t expect to be a finance whiz any more than you should expect a random person off the street to be an expert at your job.  Companies employ entire departments to create budgets, manage risk, raise capital, make long-term investments, maintain compliance, and handle reporting. Strong financial planning and operations help companies minimize risk and maximize upside.  Tech people have a similar job to be done. You need to forecast liquidity, pay taxes, source financing/refinancing, and protect your savings. Even the most financially skilled among us cannot run our own fully optimized personal finance departments.  Both legacy financial institutions and mass-market robo-advisors miss the mark.  The largest banks in the world can’t figure out how to make your portfolio seamlessly accessible on your phone. Traditional RIAs treat you exactly like they would treat a dentist (and know as much as your dentist does about NSOs).  Robo-advisors have decent interfaces but can’t offer any meaningful advice about key areas like option exercising, tax consequences, and angel investing. Googling any of these topics drops you in a sea of SEO spam. You’re left relying upon Slack and Hacker News threads as you make your most important financial decisions.  We founded Compound to solve these problems and go beyond what traditional banks and advisors have to offer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La puntuación de veracidad del texto es: 15\n"
     ]
    }
   ],
   "source": [
    "# Obtener las columnas de palabras y porcentajes\n",
    "palabra_column = 'palabra'\n",
    "falso_column = 'porcentaje_falso'\n",
    "verdadero_column = 'porcentaje_verdadero'\n",
    "\n",
    "# Crear una matriz de características con los porcentajes\n",
    "X = df_resultado[[falso_column, verdadero_column]].values\n",
    "\n",
    "# Crear una variable objetivo con la puntuación de veracidad\n",
    "y = df_resultado[verdadero_column].values\n",
    "\n",
    "# Crear y entrenar el modelo de Bosques Aleatorios\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Pedir al usuario que ingrese un texto\n",
    "texto = input('Ingrese el texto a evaluar: ')\n",
    "\n",
    "# Obtener las palabras del texto\n",
    "palabras_texto = texto.split()\n",
    "\n",
    "# Calcular la puntuación de veracidad del texto\n",
    "puntuacion = 0\n",
    "for palabra in palabras_texto:\n",
    "    if palabra in df_resultado[palabra_column].values:\n",
    "        porcentaje_falso = df_resultado[df_resultado[palabra_column] == palabra][falso_column].values[0]\n",
    "        porcentaje_verdadero = df_resultado[df_resultado[palabra_column] == palabra][verdadero_column].values[0]\n",
    "        prediccion = rf_model.predict([[porcentaje_falso, porcentaje_verdadero]])[0]\n",
    "        puntuacion += prediccion\n",
    "\n",
    "# Ajustar la puntuación a una escala del 0 al 15\n",
    "puntuacion = max(0, min(puntuacion, 15))\n",
    "\n",
    "# Imprimir la puntuación de veracidad del texto\n",
    "print('La puntuación de veracidad del texto es:', puntuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedir al usuario que ingrese un texto\n",
    "texto = input('Ingrese el texto a evaluar: ')\n",
    "\n",
    "# Obtener las palabras del texto\n",
    "palabras_texto = texto.split()\n",
    "\n",
    "# Calcular la puntuación de veracidad del texto\n",
    "puntuacion = 0\n",
    "for palabra in palabras_texto:\n",
    "    if palabra in df_resultado[palabra_column].values:\n",
    "        porcentaje_falso = df_resultado[df_resultado[palabra_column] == palabra][falso_column].values[0]\n",
    "        porcentaje_verdadero = df_resultado[df_resultado[palabra_column] == palabra][verdadero_column].values[0]\n",
    "        prediccion = rf_model.predict([[porcentaje_falso, porcentaje_verdadero]])[0]\n",
    "        puntuacion += prediccion\n",
    "\n",
    "# Ajustar la puntuación a una escala del 0 al 15\n",
    "puntuacion = max(0, min(puntuacion, 15))\n",
    "\n",
    "# Imprimir la puntuación de veracidad del texto\n",
    "print('La puntuación de veracidad del texto es:', puntuacion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
